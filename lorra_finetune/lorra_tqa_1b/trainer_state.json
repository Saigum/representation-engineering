{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3753,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007993605115907274,
      "grad_norm": 1.2506023645401,
      "learning_rate": 0.0003,
      "loss": 0.3249,
      "step": 10
    },
    {
      "epoch": 0.01598721023181455,
      "grad_norm": 2.052670955657959,
      "learning_rate": 0.0003,
      "loss": 0.2956,
      "step": 20
    },
    {
      "epoch": 0.023980815347721823,
      "grad_norm": 1.5514862537384033,
      "learning_rate": 0.0003,
      "loss": 0.2759,
      "step": 30
    },
    {
      "epoch": 0.0319744204636291,
      "grad_norm": 0.7780788540840149,
      "learning_rate": 0.0003,
      "loss": 0.2855,
      "step": 40
    },
    {
      "epoch": 0.03996802557953637,
      "grad_norm": 1.3599660396575928,
      "learning_rate": 0.0003,
      "loss": 0.2831,
      "step": 50
    },
    {
      "epoch": 0.047961630695443645,
      "grad_norm": 1.2056044340133667,
      "learning_rate": 0.0003,
      "loss": 0.2885,
      "step": 60
    },
    {
      "epoch": 0.055955235811350916,
      "grad_norm": 2.095498561859131,
      "learning_rate": 0.0003,
      "loss": 0.2777,
      "step": 70
    },
    {
      "epoch": 0.0639488409272582,
      "grad_norm": 1.3459166288375854,
      "learning_rate": 0.0003,
      "loss": 0.2732,
      "step": 80
    },
    {
      "epoch": 0.07194244604316546,
      "grad_norm": 0.8905148506164551,
      "learning_rate": 0.0003,
      "loss": 0.268,
      "step": 90
    },
    {
      "epoch": 0.07993605115907274,
      "grad_norm": 0.8884658217430115,
      "learning_rate": 0.0003,
      "loss": 0.2643,
      "step": 100
    },
    {
      "epoch": 0.08792965627498002,
      "grad_norm": 1.2352523803710938,
      "learning_rate": 0.0003,
      "loss": 0.2504,
      "step": 110
    },
    {
      "epoch": 0.09592326139088729,
      "grad_norm": 1.0262775421142578,
      "learning_rate": 0.0003,
      "loss": 0.277,
      "step": 120
    },
    {
      "epoch": 0.10391686650679456,
      "grad_norm": 1.0180351734161377,
      "learning_rate": 0.0003,
      "loss": 0.2664,
      "step": 130
    },
    {
      "epoch": 0.11191047162270183,
      "grad_norm": 1.1577720642089844,
      "learning_rate": 0.0003,
      "loss": 0.2736,
      "step": 140
    },
    {
      "epoch": 0.11990407673860912,
      "grad_norm": 1.0008068084716797,
      "learning_rate": 0.0003,
      "loss": 0.2735,
      "step": 150
    },
    {
      "epoch": 0.1278976818545164,
      "grad_norm": 0.8646596670150757,
      "learning_rate": 0.0003,
      "loss": 0.266,
      "step": 160
    },
    {
      "epoch": 0.13589128697042366,
      "grad_norm": 0.8861970901489258,
      "learning_rate": 0.0003,
      "loss": 0.2585,
      "step": 170
    },
    {
      "epoch": 0.14388489208633093,
      "grad_norm": 0.5600900053977966,
      "learning_rate": 0.0003,
      "loss": 0.2429,
      "step": 180
    },
    {
      "epoch": 0.1518784972022382,
      "grad_norm": 1.0292980670928955,
      "learning_rate": 0.0003,
      "loss": 0.2696,
      "step": 190
    },
    {
      "epoch": 0.15987210231814547,
      "grad_norm": 1.1351977586746216,
      "learning_rate": 0.0003,
      "loss": 0.2536,
      "step": 200
    },
    {
      "epoch": 0.16786570743405277,
      "grad_norm": 1.2478814125061035,
      "learning_rate": 0.0003,
      "loss": 0.2465,
      "step": 210
    },
    {
      "epoch": 0.17585931254996004,
      "grad_norm": 0.8787986040115356,
      "learning_rate": 0.0003,
      "loss": 0.2736,
      "step": 220
    },
    {
      "epoch": 0.1838529176658673,
      "grad_norm": 0.8713589310646057,
      "learning_rate": 0.0003,
      "loss": 0.2617,
      "step": 230
    },
    {
      "epoch": 0.19184652278177458,
      "grad_norm": 1.0090991258621216,
      "learning_rate": 0.0003,
      "loss": 0.2663,
      "step": 240
    },
    {
      "epoch": 0.19984012789768185,
      "grad_norm": 1.0601623058319092,
      "learning_rate": 0.0003,
      "loss": 0.2558,
      "step": 250
    },
    {
      "epoch": 0.20783373301358912,
      "grad_norm": 0.6883893013000488,
      "learning_rate": 0.0003,
      "loss": 0.26,
      "step": 260
    },
    {
      "epoch": 0.2158273381294964,
      "grad_norm": 0.9747909903526306,
      "learning_rate": 0.0003,
      "loss": 0.2666,
      "step": 270
    },
    {
      "epoch": 0.22382094324540366,
      "grad_norm": 0.6613208651542664,
      "learning_rate": 0.0003,
      "loss": 0.281,
      "step": 280
    },
    {
      "epoch": 0.23181454836131096,
      "grad_norm": 1.0458874702453613,
      "learning_rate": 0.0003,
      "loss": 0.243,
      "step": 290
    },
    {
      "epoch": 0.23980815347721823,
      "grad_norm": 1.0678398609161377,
      "learning_rate": 0.0003,
      "loss": 0.2691,
      "step": 300
    },
    {
      "epoch": 0.2478017585931255,
      "grad_norm": 0.6821151375770569,
      "learning_rate": 0.0003,
      "loss": 0.2362,
      "step": 310
    },
    {
      "epoch": 0.2557953637090328,
      "grad_norm": 1.0003048181533813,
      "learning_rate": 0.0003,
      "loss": 0.2478,
      "step": 320
    },
    {
      "epoch": 0.2637889688249401,
      "grad_norm": 0.796734094619751,
      "learning_rate": 0.0003,
      "loss": 0.2589,
      "step": 330
    },
    {
      "epoch": 0.2717825739408473,
      "grad_norm": 0.8087043762207031,
      "learning_rate": 0.0003,
      "loss": 0.2555,
      "step": 340
    },
    {
      "epoch": 0.2797761790567546,
      "grad_norm": 1.1421819925308228,
      "learning_rate": 0.0003,
      "loss": 0.2917,
      "step": 350
    },
    {
      "epoch": 0.28776978417266186,
      "grad_norm": 1.036325216293335,
      "learning_rate": 0.0003,
      "loss": 0.2572,
      "step": 360
    },
    {
      "epoch": 0.29576338928856916,
      "grad_norm": 0.8338972330093384,
      "learning_rate": 0.0003,
      "loss": 0.2718,
      "step": 370
    },
    {
      "epoch": 0.3037569944044764,
      "grad_norm": 0.7393480539321899,
      "learning_rate": 0.0003,
      "loss": 0.2654,
      "step": 380
    },
    {
      "epoch": 0.3117505995203837,
      "grad_norm": 1.0481959581375122,
      "learning_rate": 0.0003,
      "loss": 0.2713,
      "step": 390
    },
    {
      "epoch": 0.31974420463629094,
      "grad_norm": 0.7994272112846375,
      "learning_rate": 0.0003,
      "loss": 0.2711,
      "step": 400
    },
    {
      "epoch": 0.32773780975219824,
      "grad_norm": 0.6484119892120361,
      "learning_rate": 0.0003,
      "loss": 0.2481,
      "step": 410
    },
    {
      "epoch": 0.33573141486810554,
      "grad_norm": 1.1198561191558838,
      "learning_rate": 0.0003,
      "loss": 0.2535,
      "step": 420
    },
    {
      "epoch": 0.3437250199840128,
      "grad_norm": 0.9339818954467773,
      "learning_rate": 0.0003,
      "loss": 0.2664,
      "step": 430
    },
    {
      "epoch": 0.3517186250999201,
      "grad_norm": 0.7827150821685791,
      "learning_rate": 0.0003,
      "loss": 0.251,
      "step": 440
    },
    {
      "epoch": 0.3597122302158273,
      "grad_norm": 0.8402258157730103,
      "learning_rate": 0.0003,
      "loss": 0.2687,
      "step": 450
    },
    {
      "epoch": 0.3677058353317346,
      "grad_norm": 0.9269120097160339,
      "learning_rate": 0.0003,
      "loss": 0.263,
      "step": 460
    },
    {
      "epoch": 0.37569944044764186,
      "grad_norm": 1.10263192653656,
      "learning_rate": 0.0003,
      "loss": 0.2695,
      "step": 470
    },
    {
      "epoch": 0.38369304556354916,
      "grad_norm": 0.7528501152992249,
      "learning_rate": 0.0003,
      "loss": 0.2631,
      "step": 480
    },
    {
      "epoch": 0.39168665067945646,
      "grad_norm": 1.1706516742706299,
      "learning_rate": 0.0003,
      "loss": 0.2669,
      "step": 490
    },
    {
      "epoch": 0.3996802557953637,
      "grad_norm": 0.7906644940376282,
      "learning_rate": 0.0003,
      "loss": 0.2568,
      "step": 500
    },
    {
      "epoch": 0.407673860911271,
      "grad_norm": 0.7264963984489441,
      "learning_rate": 0.0003,
      "loss": 0.2777,
      "step": 510
    },
    {
      "epoch": 0.41566746602717825,
      "grad_norm": 1.1227940320968628,
      "learning_rate": 0.0003,
      "loss": 0.2783,
      "step": 520
    },
    {
      "epoch": 0.42366107114308554,
      "grad_norm": 1.0327023267745972,
      "learning_rate": 0.0003,
      "loss": 0.2664,
      "step": 530
    },
    {
      "epoch": 0.4316546762589928,
      "grad_norm": 0.9523527026176453,
      "learning_rate": 0.0003,
      "loss": 0.2718,
      "step": 540
    },
    {
      "epoch": 0.4396482813749001,
      "grad_norm": 0.7274806499481201,
      "learning_rate": 0.0003,
      "loss": 0.2584,
      "step": 550
    },
    {
      "epoch": 0.44764188649080733,
      "grad_norm": 0.6487650275230408,
      "learning_rate": 0.0003,
      "loss": 0.2548,
      "step": 560
    },
    {
      "epoch": 0.4556354916067146,
      "grad_norm": 1.0283347368240356,
      "learning_rate": 0.0003,
      "loss": 0.2543,
      "step": 570
    },
    {
      "epoch": 0.4636290967226219,
      "grad_norm": 0.9471133947372437,
      "learning_rate": 0.0003,
      "loss": 0.2512,
      "step": 580
    },
    {
      "epoch": 0.47162270183852917,
      "grad_norm": 0.7443210482597351,
      "learning_rate": 0.0003,
      "loss": 0.2494,
      "step": 590
    },
    {
      "epoch": 0.47961630695443647,
      "grad_norm": 0.548184335231781,
      "learning_rate": 0.0003,
      "loss": 0.2677,
      "step": 600
    },
    {
      "epoch": 0.4876099120703437,
      "grad_norm": 0.5373222827911377,
      "learning_rate": 0.0003,
      "loss": 0.2381,
      "step": 610
    },
    {
      "epoch": 0.495603517186251,
      "grad_norm": 1.1683038473129272,
      "learning_rate": 0.0003,
      "loss": 0.2424,
      "step": 620
    },
    {
      "epoch": 0.5035971223021583,
      "grad_norm": 0.6556346416473389,
      "learning_rate": 0.0003,
      "loss": 0.2512,
      "step": 630
    },
    {
      "epoch": 0.5115907274180655,
      "grad_norm": 1.0582510232925415,
      "learning_rate": 0.0003,
      "loss": 0.2593,
      "step": 640
    },
    {
      "epoch": 0.5195843325339728,
      "grad_norm": 0.7756739854812622,
      "learning_rate": 0.0003,
      "loss": 0.2618,
      "step": 650
    },
    {
      "epoch": 0.5275779376498801,
      "grad_norm": 1.146811604499817,
      "learning_rate": 0.0003,
      "loss": 0.2715,
      "step": 660
    },
    {
      "epoch": 0.5355715427657873,
      "grad_norm": 0.7700884342193604,
      "learning_rate": 0.0003,
      "loss": 0.2706,
      "step": 670
    },
    {
      "epoch": 0.5435651478816946,
      "grad_norm": 0.7658644318580627,
      "learning_rate": 0.0003,
      "loss": 0.2705,
      "step": 680
    },
    {
      "epoch": 0.5515587529976019,
      "grad_norm": 1.066565752029419,
      "learning_rate": 0.0003,
      "loss": 0.2534,
      "step": 690
    },
    {
      "epoch": 0.5595523581135092,
      "grad_norm": 0.7045055031776428,
      "learning_rate": 0.0003,
      "loss": 0.2592,
      "step": 700
    },
    {
      "epoch": 0.5675459632294164,
      "grad_norm": 0.8009112477302551,
      "learning_rate": 0.0003,
      "loss": 0.2632,
      "step": 710
    },
    {
      "epoch": 0.5755395683453237,
      "grad_norm": 0.811027467250824,
      "learning_rate": 0.0003,
      "loss": 0.2588,
      "step": 720
    },
    {
      "epoch": 0.583533173461231,
      "grad_norm": 0.8417820334434509,
      "learning_rate": 0.0003,
      "loss": 0.2578,
      "step": 730
    },
    {
      "epoch": 0.5915267785771383,
      "grad_norm": 0.6953643560409546,
      "learning_rate": 0.0003,
      "loss": 0.2587,
      "step": 740
    },
    {
      "epoch": 0.5995203836930456,
      "grad_norm": 0.8617641925811768,
      "learning_rate": 0.0003,
      "loss": 0.2444,
      "step": 750
    },
    {
      "epoch": 0.6075139888089528,
      "grad_norm": 1.1563687324523926,
      "learning_rate": 0.0003,
      "loss": 0.2599,
      "step": 760
    },
    {
      "epoch": 0.6155075939248601,
      "grad_norm": 1.209421992301941,
      "learning_rate": 0.0003,
      "loss": 0.253,
      "step": 770
    },
    {
      "epoch": 0.6235011990407674,
      "grad_norm": 1.1246609687805176,
      "learning_rate": 0.0003,
      "loss": 0.2329,
      "step": 780
    },
    {
      "epoch": 0.6314948041566747,
      "grad_norm": 0.5692287683486938,
      "learning_rate": 0.0003,
      "loss": 0.2607,
      "step": 790
    },
    {
      "epoch": 0.6394884092725819,
      "grad_norm": 0.8057538270950317,
      "learning_rate": 0.0003,
      "loss": 0.2431,
      "step": 800
    },
    {
      "epoch": 0.6474820143884892,
      "grad_norm": 0.888584315776825,
      "learning_rate": 0.0003,
      "loss": 0.2479,
      "step": 810
    },
    {
      "epoch": 0.6554756195043965,
      "grad_norm": 0.6891582608222961,
      "learning_rate": 0.0003,
      "loss": 0.2732,
      "step": 820
    },
    {
      "epoch": 0.6634692246203038,
      "grad_norm": 1.0065250396728516,
      "learning_rate": 0.0003,
      "loss": 0.2395,
      "step": 830
    },
    {
      "epoch": 0.6714628297362111,
      "grad_norm": 0.5164510607719421,
      "learning_rate": 0.0003,
      "loss": 0.2592,
      "step": 840
    },
    {
      "epoch": 0.6794564348521183,
      "grad_norm": 0.9983658790588379,
      "learning_rate": 0.0003,
      "loss": 0.2535,
      "step": 850
    },
    {
      "epoch": 0.6874500399680256,
      "grad_norm": 0.8643397688865662,
      "learning_rate": 0.0003,
      "loss": 0.2598,
      "step": 860
    },
    {
      "epoch": 0.6954436450839329,
      "grad_norm": 3.7805089950561523,
      "learning_rate": 0.0003,
      "loss": 0.2501,
      "step": 870
    },
    {
      "epoch": 0.7034372501998402,
      "grad_norm": 0.882504403591156,
      "learning_rate": 0.0003,
      "loss": 0.2657,
      "step": 880
    },
    {
      "epoch": 0.7114308553157475,
      "grad_norm": 0.8392139077186584,
      "learning_rate": 0.0003,
      "loss": 0.253,
      "step": 890
    },
    {
      "epoch": 0.7194244604316546,
      "grad_norm": 1.1065977811813354,
      "learning_rate": 0.0003,
      "loss": 0.25,
      "step": 900
    },
    {
      "epoch": 0.7274180655475619,
      "grad_norm": 1.0797755718231201,
      "learning_rate": 0.0003,
      "loss": 0.2574,
      "step": 910
    },
    {
      "epoch": 0.7354116706634692,
      "grad_norm": 0.8299031853675842,
      "learning_rate": 0.0003,
      "loss": 0.2726,
      "step": 920
    },
    {
      "epoch": 0.7434052757793765,
      "grad_norm": 0.7467309236526489,
      "learning_rate": 0.0003,
      "loss": 0.2372,
      "step": 930
    },
    {
      "epoch": 0.7513988808952837,
      "grad_norm": 1.009684681892395,
      "learning_rate": 0.0003,
      "loss": 0.2557,
      "step": 940
    },
    {
      "epoch": 0.759392486011191,
      "grad_norm": 1.2682610750198364,
      "learning_rate": 0.0003,
      "loss": 0.2539,
      "step": 950
    },
    {
      "epoch": 0.7673860911270983,
      "grad_norm": 0.8172616362571716,
      "learning_rate": 0.0003,
      "loss": 0.2559,
      "step": 960
    },
    {
      "epoch": 0.7753796962430056,
      "grad_norm": 0.9736186861991882,
      "learning_rate": 0.0003,
      "loss": 0.251,
      "step": 970
    },
    {
      "epoch": 0.7833733013589129,
      "grad_norm": 0.9263557195663452,
      "learning_rate": 0.0003,
      "loss": 0.2467,
      "step": 980
    },
    {
      "epoch": 0.7913669064748201,
      "grad_norm": 0.9099889397621155,
      "learning_rate": 0.0003,
      "loss": 0.2427,
      "step": 990
    },
    {
      "epoch": 0.7993605115907274,
      "grad_norm": 1.0803449153900146,
      "learning_rate": 0.0003,
      "loss": 0.2522,
      "step": 1000
    },
    {
      "epoch": 0.8073541167066347,
      "grad_norm": 0.6801181435585022,
      "learning_rate": 0.0003,
      "loss": 0.2535,
      "step": 1010
    },
    {
      "epoch": 0.815347721822542,
      "grad_norm": 1.1757524013519287,
      "learning_rate": 0.0003,
      "loss": 0.2383,
      "step": 1020
    },
    {
      "epoch": 0.8233413269384492,
      "grad_norm": 0.8923729658126831,
      "learning_rate": 0.0003,
      "loss": 0.2512,
      "step": 1030
    },
    {
      "epoch": 0.8313349320543565,
      "grad_norm": 0.5363956093788147,
      "learning_rate": 0.0003,
      "loss": 0.2479,
      "step": 1040
    },
    {
      "epoch": 0.8393285371702638,
      "grad_norm": 0.5946967005729675,
      "learning_rate": 0.0003,
      "loss": 0.232,
      "step": 1050
    },
    {
      "epoch": 0.8473221422861711,
      "grad_norm": 0.5276085734367371,
      "learning_rate": 0.0003,
      "loss": 0.2592,
      "step": 1060
    },
    {
      "epoch": 0.8553157474020784,
      "grad_norm": 0.8181144595146179,
      "learning_rate": 0.0003,
      "loss": 0.2604,
      "step": 1070
    },
    {
      "epoch": 0.8633093525179856,
      "grad_norm": 1.2040445804595947,
      "learning_rate": 0.0003,
      "loss": 0.2544,
      "step": 1080
    },
    {
      "epoch": 0.8713029576338929,
      "grad_norm": 0.8685993552207947,
      "learning_rate": 0.0003,
      "loss": 0.2456,
      "step": 1090
    },
    {
      "epoch": 0.8792965627498002,
      "grad_norm": 0.7658940553665161,
      "learning_rate": 0.0003,
      "loss": 0.239,
      "step": 1100
    },
    {
      "epoch": 0.8872901678657075,
      "grad_norm": 0.7130267024040222,
      "learning_rate": 0.0003,
      "loss": 0.253,
      "step": 1110
    },
    {
      "epoch": 0.8952837729816147,
      "grad_norm": 0.888950765132904,
      "learning_rate": 0.0003,
      "loss": 0.2698,
      "step": 1120
    },
    {
      "epoch": 0.903277378097522,
      "grad_norm": 0.7376337051391602,
      "learning_rate": 0.0003,
      "loss": 0.2833,
      "step": 1130
    },
    {
      "epoch": 0.9112709832134293,
      "grad_norm": 1.0713802576065063,
      "learning_rate": 0.0003,
      "loss": 0.2533,
      "step": 1140
    },
    {
      "epoch": 0.9192645883293366,
      "grad_norm": 0.7975802421569824,
      "learning_rate": 0.0003,
      "loss": 0.2573,
      "step": 1150
    },
    {
      "epoch": 0.9272581934452439,
      "grad_norm": 0.9274455904960632,
      "learning_rate": 0.0003,
      "loss": 0.2603,
      "step": 1160
    },
    {
      "epoch": 0.935251798561151,
      "grad_norm": 0.6396811604499817,
      "learning_rate": 0.0003,
      "loss": 0.2477,
      "step": 1170
    },
    {
      "epoch": 0.9432454036770583,
      "grad_norm": 0.9522455334663391,
      "learning_rate": 0.0003,
      "loss": 0.2613,
      "step": 1180
    },
    {
      "epoch": 0.9512390087929656,
      "grad_norm": 0.5956506133079529,
      "learning_rate": 0.0003,
      "loss": 0.2454,
      "step": 1190
    },
    {
      "epoch": 0.9592326139088729,
      "grad_norm": 0.7638036608695984,
      "learning_rate": 0.0003,
      "loss": 0.2584,
      "step": 1200
    },
    {
      "epoch": 0.9672262190247801,
      "grad_norm": 0.6558775305747986,
      "learning_rate": 0.0003,
      "loss": 0.2423,
      "step": 1210
    },
    {
      "epoch": 0.9752198241406874,
      "grad_norm": 0.6689099669456482,
      "learning_rate": 0.0003,
      "loss": 0.2734,
      "step": 1220
    },
    {
      "epoch": 0.9832134292565947,
      "grad_norm": 0.6864504218101501,
      "learning_rate": 0.0003,
      "loss": 0.2581,
      "step": 1230
    },
    {
      "epoch": 0.991207034372502,
      "grad_norm": 0.8388456702232361,
      "learning_rate": 0.0003,
      "loss": 0.2411,
      "step": 1240
    },
    {
      "epoch": 0.9992006394884093,
      "grad_norm": 0.630458414554596,
      "learning_rate": 0.0003,
      "loss": 0.2572,
      "step": 1250
    },
    {
      "epoch": 1.0071942446043165,
      "grad_norm": 1.092271089553833,
      "learning_rate": 0.0003,
      "loss": 0.2571,
      "step": 1260
    },
    {
      "epoch": 1.0151878497202238,
      "grad_norm": 0.6872824430465698,
      "learning_rate": 0.0003,
      "loss": 0.2575,
      "step": 1270
    },
    {
      "epoch": 1.023181454836131,
      "grad_norm": 1.0296372175216675,
      "learning_rate": 0.0003,
      "loss": 0.2417,
      "step": 1280
    },
    {
      "epoch": 1.0311750599520384,
      "grad_norm": 0.7012927532196045,
      "learning_rate": 0.0003,
      "loss": 0.2481,
      "step": 1290
    },
    {
      "epoch": 1.0391686650679457,
      "grad_norm": 0.818732500076294,
      "learning_rate": 0.0003,
      "loss": 0.2358,
      "step": 1300
    },
    {
      "epoch": 1.047162270183853,
      "grad_norm": 0.6989608407020569,
      "learning_rate": 0.0003,
      "loss": 0.237,
      "step": 1310
    },
    {
      "epoch": 1.0551558752997603,
      "grad_norm": 1.0211927890777588,
      "learning_rate": 0.0003,
      "loss": 0.2365,
      "step": 1320
    },
    {
      "epoch": 1.0631494804156674,
      "grad_norm": 0.6132900714874268,
      "learning_rate": 0.0003,
      "loss": 0.2356,
      "step": 1330
    },
    {
      "epoch": 1.0711430855315747,
      "grad_norm": 0.645728349685669,
      "learning_rate": 0.0003,
      "loss": 0.2527,
      "step": 1340
    },
    {
      "epoch": 1.079136690647482,
      "grad_norm": 0.7407113313674927,
      "learning_rate": 0.0003,
      "loss": 0.247,
      "step": 1350
    },
    {
      "epoch": 1.0871302957633893,
      "grad_norm": 0.7938966751098633,
      "learning_rate": 0.0003,
      "loss": 0.2654,
      "step": 1360
    },
    {
      "epoch": 1.0951239008792966,
      "grad_norm": 0.8148325085639954,
      "learning_rate": 0.0003,
      "loss": 0.2345,
      "step": 1370
    },
    {
      "epoch": 1.1031175059952039,
      "grad_norm": 0.8125836849212646,
      "learning_rate": 0.0003,
      "loss": 0.2642,
      "step": 1380
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.7552316784858704,
      "learning_rate": 0.0003,
      "loss": 0.2518,
      "step": 1390
    },
    {
      "epoch": 1.1191047162270185,
      "grad_norm": 0.6811752319335938,
      "learning_rate": 0.0003,
      "loss": 0.2341,
      "step": 1400
    },
    {
      "epoch": 1.1270983213429258,
      "grad_norm": 0.679100513458252,
      "learning_rate": 0.0003,
      "loss": 0.2409,
      "step": 1410
    },
    {
      "epoch": 1.1350919264588328,
      "grad_norm": 0.6294377446174622,
      "learning_rate": 0.0003,
      "loss": 0.2623,
      "step": 1420
    },
    {
      "epoch": 1.1430855315747401,
      "grad_norm": 0.7577739357948303,
      "learning_rate": 0.0003,
      "loss": 0.2581,
      "step": 1430
    },
    {
      "epoch": 1.1510791366906474,
      "grad_norm": 0.6307833790779114,
      "learning_rate": 0.0003,
      "loss": 0.2605,
      "step": 1440
    },
    {
      "epoch": 1.1590727418065547,
      "grad_norm": 0.7471426725387573,
      "learning_rate": 0.0003,
      "loss": 0.2608,
      "step": 1450
    },
    {
      "epoch": 1.167066346922462,
      "grad_norm": 0.7922160029411316,
      "learning_rate": 0.0003,
      "loss": 0.2578,
      "step": 1460
    },
    {
      "epoch": 1.1750599520383693,
      "grad_norm": 0.681090235710144,
      "learning_rate": 0.0003,
      "loss": 0.2446,
      "step": 1470
    },
    {
      "epoch": 1.1830535571542766,
      "grad_norm": 1.1248791217803955,
      "learning_rate": 0.0003,
      "loss": 0.2475,
      "step": 1480
    },
    {
      "epoch": 1.191047162270184,
      "grad_norm": 0.8250086307525635,
      "learning_rate": 0.0003,
      "loss": 0.2694,
      "step": 1490
    },
    {
      "epoch": 1.1990407673860912,
      "grad_norm": 0.7021396160125732,
      "learning_rate": 0.0003,
      "loss": 0.2539,
      "step": 1500
    },
    {
      "epoch": 1.2070343725019983,
      "grad_norm": 0.888500452041626,
      "learning_rate": 0.0003,
      "loss": 0.2385,
      "step": 1510
    },
    {
      "epoch": 1.2150279776179056,
      "grad_norm": 0.6190073490142822,
      "learning_rate": 0.0003,
      "loss": 0.2569,
      "step": 1520
    },
    {
      "epoch": 1.223021582733813,
      "grad_norm": 0.94577956199646,
      "learning_rate": 0.0003,
      "loss": 0.2734,
      "step": 1530
    },
    {
      "epoch": 1.2310151878497202,
      "grad_norm": 0.600827693939209,
      "learning_rate": 0.0003,
      "loss": 0.2363,
      "step": 1540
    },
    {
      "epoch": 1.2390087929656275,
      "grad_norm": 0.6280469298362732,
      "learning_rate": 0.0003,
      "loss": 0.2616,
      "step": 1550
    },
    {
      "epoch": 1.2470023980815348,
      "grad_norm": 0.9864698052406311,
      "learning_rate": 0.0003,
      "loss": 0.2529,
      "step": 1560
    },
    {
      "epoch": 1.254996003197442,
      "grad_norm": 0.8060300946235657,
      "learning_rate": 0.0003,
      "loss": 0.241,
      "step": 1570
    },
    {
      "epoch": 1.2629896083133494,
      "grad_norm": 1.0194354057312012,
      "learning_rate": 0.0003,
      "loss": 0.2351,
      "step": 1580
    },
    {
      "epoch": 1.2709832134292567,
      "grad_norm": 0.6186793446540833,
      "learning_rate": 0.0003,
      "loss": 0.2416,
      "step": 1590
    },
    {
      "epoch": 1.2789768185451638,
      "grad_norm": 0.7694095373153687,
      "learning_rate": 0.0003,
      "loss": 0.2466,
      "step": 1600
    },
    {
      "epoch": 1.286970423661071,
      "grad_norm": 0.7928156852722168,
      "learning_rate": 0.0003,
      "loss": 0.2348,
      "step": 1610
    },
    {
      "epoch": 1.2949640287769784,
      "grad_norm": 0.8592666387557983,
      "learning_rate": 0.0003,
      "loss": 0.2549,
      "step": 1620
    },
    {
      "epoch": 1.3029576338928857,
      "grad_norm": 0.70963454246521,
      "learning_rate": 0.0003,
      "loss": 0.251,
      "step": 1630
    },
    {
      "epoch": 1.310951239008793,
      "grad_norm": 0.7585949897766113,
      "learning_rate": 0.0003,
      "loss": 0.2432,
      "step": 1640
    },
    {
      "epoch": 1.3189448441247003,
      "grad_norm": 0.6043020486831665,
      "learning_rate": 0.0003,
      "loss": 0.2535,
      "step": 1650
    },
    {
      "epoch": 1.3269384492406076,
      "grad_norm": 0.42189881205558777,
      "learning_rate": 0.0003,
      "loss": 0.2583,
      "step": 1660
    },
    {
      "epoch": 1.3349320543565149,
      "grad_norm": 0.6877878904342651,
      "learning_rate": 0.0003,
      "loss": 0.2348,
      "step": 1670
    },
    {
      "epoch": 1.3429256594724222,
      "grad_norm": 0.8786725997924805,
      "learning_rate": 0.0003,
      "loss": 0.2463,
      "step": 1680
    },
    {
      "epoch": 1.3509192645883292,
      "grad_norm": 0.7497994899749756,
      "learning_rate": 0.0003,
      "loss": 0.2311,
      "step": 1690
    },
    {
      "epoch": 1.3589128697042367,
      "grad_norm": 1.3613853454589844,
      "learning_rate": 0.0003,
      "loss": 0.2481,
      "step": 1700
    },
    {
      "epoch": 1.3669064748201438,
      "grad_norm": 0.853812038898468,
      "learning_rate": 0.0003,
      "loss": 0.2573,
      "step": 1710
    },
    {
      "epoch": 1.3749000799360511,
      "grad_norm": 0.5916637182235718,
      "learning_rate": 0.0003,
      "loss": 0.244,
      "step": 1720
    },
    {
      "epoch": 1.3828936850519584,
      "grad_norm": 0.8231180310249329,
      "learning_rate": 0.0003,
      "loss": 0.2401,
      "step": 1730
    },
    {
      "epoch": 1.3908872901678657,
      "grad_norm": 1.3021926879882812,
      "learning_rate": 0.0003,
      "loss": 0.2344,
      "step": 1740
    },
    {
      "epoch": 1.398880895283773,
      "grad_norm": 0.8792489171028137,
      "learning_rate": 0.0003,
      "loss": 0.2451,
      "step": 1750
    },
    {
      "epoch": 1.4068745003996803,
      "grad_norm": 0.7558155059814453,
      "learning_rate": 0.0003,
      "loss": 0.2556,
      "step": 1760
    },
    {
      "epoch": 1.4148681055155876,
      "grad_norm": 0.9534040689468384,
      "learning_rate": 0.0003,
      "loss": 0.252,
      "step": 1770
    },
    {
      "epoch": 1.4228617106314947,
      "grad_norm": 0.8133562207221985,
      "learning_rate": 0.0003,
      "loss": 0.2541,
      "step": 1780
    },
    {
      "epoch": 1.4308553157474022,
      "grad_norm": 1.2399094104766846,
      "learning_rate": 0.0003,
      "loss": 0.2564,
      "step": 1790
    },
    {
      "epoch": 1.4388489208633093,
      "grad_norm": 1.0172852277755737,
      "learning_rate": 0.0003,
      "loss": 0.2483,
      "step": 1800
    },
    {
      "epoch": 1.4468425259792166,
      "grad_norm": 0.6024949550628662,
      "learning_rate": 0.0003,
      "loss": 0.2496,
      "step": 1810
    },
    {
      "epoch": 1.4548361310951239,
      "grad_norm": 1.0100221633911133,
      "learning_rate": 0.0003,
      "loss": 0.2521,
      "step": 1820
    },
    {
      "epoch": 1.4628297362110312,
      "grad_norm": 1.1049600839614868,
      "learning_rate": 0.0003,
      "loss": 0.2443,
      "step": 1830
    },
    {
      "epoch": 1.4708233413269385,
      "grad_norm": 0.7424181699752808,
      "learning_rate": 0.0003,
      "loss": 0.2539,
      "step": 1840
    },
    {
      "epoch": 1.4788169464428458,
      "grad_norm": 0.6759803891181946,
      "learning_rate": 0.0003,
      "loss": 0.2375,
      "step": 1850
    },
    {
      "epoch": 1.486810551558753,
      "grad_norm": 0.6108483076095581,
      "learning_rate": 0.0003,
      "loss": 0.2628,
      "step": 1860
    },
    {
      "epoch": 1.4948041566746602,
      "grad_norm": 0.6728314757347107,
      "learning_rate": 0.0003,
      "loss": 0.2465,
      "step": 1870
    },
    {
      "epoch": 1.5027977617905677,
      "grad_norm": 0.8950538635253906,
      "learning_rate": 0.0003,
      "loss": 0.2507,
      "step": 1880
    },
    {
      "epoch": 1.5107913669064748,
      "grad_norm": 0.6608937978744507,
      "learning_rate": 0.0003,
      "loss": 0.2512,
      "step": 1890
    },
    {
      "epoch": 1.518784972022382,
      "grad_norm": 0.7163115739822388,
      "learning_rate": 0.0003,
      "loss": 0.2532,
      "step": 1900
    },
    {
      "epoch": 1.5267785771382894,
      "grad_norm": 1.4081239700317383,
      "learning_rate": 0.0003,
      "loss": 0.2543,
      "step": 1910
    },
    {
      "epoch": 1.5347721822541966,
      "grad_norm": 0.6614304184913635,
      "learning_rate": 0.0003,
      "loss": 0.2479,
      "step": 1920
    },
    {
      "epoch": 1.542765787370104,
      "grad_norm": 0.8266942501068115,
      "learning_rate": 0.0003,
      "loss": 0.2458,
      "step": 1930
    },
    {
      "epoch": 1.5507593924860112,
      "grad_norm": 0.7060965299606323,
      "learning_rate": 0.0003,
      "loss": 0.2498,
      "step": 1940
    },
    {
      "epoch": 1.5587529976019185,
      "grad_norm": 0.9422364234924316,
      "learning_rate": 0.0003,
      "loss": 0.2502,
      "step": 1950
    },
    {
      "epoch": 1.5667466027178256,
      "grad_norm": 1.0514875650405884,
      "learning_rate": 0.0003,
      "loss": 0.2482,
      "step": 1960
    },
    {
      "epoch": 1.5747402078337331,
      "grad_norm": 0.7574167251586914,
      "learning_rate": 0.0003,
      "loss": 0.2523,
      "step": 1970
    },
    {
      "epoch": 1.5827338129496402,
      "grad_norm": 0.9240683913230896,
      "learning_rate": 0.0003,
      "loss": 0.2596,
      "step": 1980
    },
    {
      "epoch": 1.5907274180655475,
      "grad_norm": 1.1001815795898438,
      "learning_rate": 0.0003,
      "loss": 0.2387,
      "step": 1990
    },
    {
      "epoch": 1.5987210231814548,
      "grad_norm": 0.8040285706520081,
      "learning_rate": 0.0003,
      "loss": 0.2286,
      "step": 2000
    },
    {
      "epoch": 1.6067146282973621,
      "grad_norm": 0.5700644254684448,
      "learning_rate": 0.0003,
      "loss": 0.2316,
      "step": 2010
    },
    {
      "epoch": 1.6147082334132694,
      "grad_norm": 0.9556148052215576,
      "learning_rate": 0.0003,
      "loss": 0.2552,
      "step": 2020
    },
    {
      "epoch": 1.6227018385291767,
      "grad_norm": 1.0027416944503784,
      "learning_rate": 0.0003,
      "loss": 0.2538,
      "step": 2030
    },
    {
      "epoch": 1.630695443645084,
      "grad_norm": 1.0073821544647217,
      "learning_rate": 0.0003,
      "loss": 0.2596,
      "step": 2040
    },
    {
      "epoch": 1.638689048760991,
      "grad_norm": 0.616571843624115,
      "learning_rate": 0.0003,
      "loss": 0.2555,
      "step": 2050
    },
    {
      "epoch": 1.6466826538768986,
      "grad_norm": 1.2657967805862427,
      "learning_rate": 0.0003,
      "loss": 0.2477,
      "step": 2060
    },
    {
      "epoch": 1.6546762589928057,
      "grad_norm": 0.8989958763122559,
      "learning_rate": 0.0003,
      "loss": 0.241,
      "step": 2070
    },
    {
      "epoch": 1.662669864108713,
      "grad_norm": 0.7271071672439575,
      "learning_rate": 0.0003,
      "loss": 0.2385,
      "step": 2080
    },
    {
      "epoch": 1.6706634692246203,
      "grad_norm": 1.2545664310455322,
      "learning_rate": 0.0003,
      "loss": 0.2673,
      "step": 2090
    },
    {
      "epoch": 1.6786570743405276,
      "grad_norm": 1.139165997505188,
      "learning_rate": 0.0003,
      "loss": 0.2479,
      "step": 2100
    },
    {
      "epoch": 1.6866506794564349,
      "grad_norm": 1.2071263790130615,
      "learning_rate": 0.0003,
      "loss": 0.252,
      "step": 2110
    },
    {
      "epoch": 1.6946442845723422,
      "grad_norm": 0.8966135382652283,
      "learning_rate": 0.0003,
      "loss": 0.2506,
      "step": 2120
    },
    {
      "epoch": 1.7026378896882495,
      "grad_norm": 0.9432867765426636,
      "learning_rate": 0.0003,
      "loss": 0.2505,
      "step": 2130
    },
    {
      "epoch": 1.7106314948041565,
      "grad_norm": 1.0134726762771606,
      "learning_rate": 0.0003,
      "loss": 0.2359,
      "step": 2140
    },
    {
      "epoch": 1.718625099920064,
      "grad_norm": 0.749383270740509,
      "learning_rate": 0.0003,
      "loss": 0.2622,
      "step": 2150
    },
    {
      "epoch": 1.7266187050359711,
      "grad_norm": 0.7721127271652222,
      "learning_rate": 0.0003,
      "loss": 0.2482,
      "step": 2160
    },
    {
      "epoch": 1.7346123101518784,
      "grad_norm": 0.9677919745445251,
      "learning_rate": 0.0003,
      "loss": 0.2471,
      "step": 2170
    },
    {
      "epoch": 1.7426059152677857,
      "grad_norm": 0.8215863704681396,
      "learning_rate": 0.0003,
      "loss": 0.2565,
      "step": 2180
    },
    {
      "epoch": 1.750599520383693,
      "grad_norm": 0.8130255341529846,
      "learning_rate": 0.0003,
      "loss": 0.2346,
      "step": 2190
    },
    {
      "epoch": 1.7585931254996003,
      "grad_norm": 1.4501614570617676,
      "learning_rate": 0.0003,
      "loss": 0.2635,
      "step": 2200
    },
    {
      "epoch": 1.7665867306155076,
      "grad_norm": 0.9511823654174805,
      "learning_rate": 0.0003,
      "loss": 0.2381,
      "step": 2210
    },
    {
      "epoch": 1.774580335731415,
      "grad_norm": 0.7557488083839417,
      "learning_rate": 0.0003,
      "loss": 0.2528,
      "step": 2220
    },
    {
      "epoch": 1.782573940847322,
      "grad_norm": 0.6905315518379211,
      "learning_rate": 0.0003,
      "loss": 0.2525,
      "step": 2230
    },
    {
      "epoch": 1.7905675459632295,
      "grad_norm": 1.177112340927124,
      "learning_rate": 0.0003,
      "loss": 0.2668,
      "step": 2240
    },
    {
      "epoch": 1.7985611510791366,
      "grad_norm": 0.9625129103660583,
      "learning_rate": 0.0003,
      "loss": 0.2507,
      "step": 2250
    },
    {
      "epoch": 1.8065547561950441,
      "grad_norm": 1.044119954109192,
      "learning_rate": 0.0003,
      "loss": 0.2478,
      "step": 2260
    },
    {
      "epoch": 1.8145483613109512,
      "grad_norm": 1.5249041318893433,
      "learning_rate": 0.0003,
      "loss": 0.2314,
      "step": 2270
    },
    {
      "epoch": 1.8225419664268585,
      "grad_norm": 0.7411582469940186,
      "learning_rate": 0.0003,
      "loss": 0.2451,
      "step": 2280
    },
    {
      "epoch": 1.8305355715427658,
      "grad_norm": 0.5813854932785034,
      "learning_rate": 0.0003,
      "loss": 0.2395,
      "step": 2290
    },
    {
      "epoch": 1.838529176658673,
      "grad_norm": 0.7391552329063416,
      "learning_rate": 0.0003,
      "loss": 0.2402,
      "step": 2300
    },
    {
      "epoch": 1.8465227817745804,
      "grad_norm": 0.6397717595100403,
      "learning_rate": 0.0003,
      "loss": 0.2324,
      "step": 2310
    },
    {
      "epoch": 1.8545163868904875,
      "grad_norm": 0.994569718837738,
      "learning_rate": 0.0003,
      "loss": 0.2519,
      "step": 2320
    },
    {
      "epoch": 1.862509992006395,
      "grad_norm": 0.5953330397605896,
      "learning_rate": 0.0003,
      "loss": 0.2393,
      "step": 2330
    },
    {
      "epoch": 1.870503597122302,
      "grad_norm": 0.7881169319152832,
      "learning_rate": 0.0003,
      "loss": 0.2566,
      "step": 2340
    },
    {
      "epoch": 1.8784972022382096,
      "grad_norm": 0.7187684774398804,
      "learning_rate": 0.0003,
      "loss": 0.239,
      "step": 2350
    },
    {
      "epoch": 1.8864908073541167,
      "grad_norm": 0.822525143623352,
      "learning_rate": 0.0003,
      "loss": 0.2416,
      "step": 2360
    },
    {
      "epoch": 1.894484412470024,
      "grad_norm": 0.570831298828125,
      "learning_rate": 0.0003,
      "loss": 0.2408,
      "step": 2370
    },
    {
      "epoch": 1.9024780175859313,
      "grad_norm": 1.2127220630645752,
      "learning_rate": 0.0003,
      "loss": 0.2588,
      "step": 2380
    },
    {
      "epoch": 1.9104716227018386,
      "grad_norm": 1.2090706825256348,
      "learning_rate": 0.0003,
      "loss": 0.2429,
      "step": 2390
    },
    {
      "epoch": 1.9184652278177459,
      "grad_norm": 0.90448397397995,
      "learning_rate": 0.0003,
      "loss": 0.2513,
      "step": 2400
    },
    {
      "epoch": 1.926458832933653,
      "grad_norm": 0.8786550164222717,
      "learning_rate": 0.0003,
      "loss": 0.2398,
      "step": 2410
    },
    {
      "epoch": 1.9344524380495605,
      "grad_norm": 0.798822283744812,
      "learning_rate": 0.0003,
      "loss": 0.247,
      "step": 2420
    },
    {
      "epoch": 1.9424460431654675,
      "grad_norm": 1.0520923137664795,
      "learning_rate": 0.0003,
      "loss": 0.2443,
      "step": 2430
    },
    {
      "epoch": 1.950439648281375,
      "grad_norm": 0.6145363450050354,
      "learning_rate": 0.0003,
      "loss": 0.2421,
      "step": 2440
    },
    {
      "epoch": 1.9584332533972821,
      "grad_norm": 0.8356128334999084,
      "learning_rate": 0.0003,
      "loss": 0.2477,
      "step": 2450
    },
    {
      "epoch": 1.9664268585131894,
      "grad_norm": 0.8064932823181152,
      "learning_rate": 0.0003,
      "loss": 0.2537,
      "step": 2460
    },
    {
      "epoch": 1.9744204636290967,
      "grad_norm": 0.67894446849823,
      "learning_rate": 0.0003,
      "loss": 0.2465,
      "step": 2470
    },
    {
      "epoch": 1.982414068745004,
      "grad_norm": 0.6265364289283752,
      "learning_rate": 0.0003,
      "loss": 0.2584,
      "step": 2480
    },
    {
      "epoch": 1.9904076738609113,
      "grad_norm": 0.7164938449859619,
      "learning_rate": 0.0003,
      "loss": 0.2359,
      "step": 2490
    },
    {
      "epoch": 1.9984012789768184,
      "grad_norm": 1.0285753011703491,
      "learning_rate": 0.0003,
      "loss": 0.2446,
      "step": 2500
    },
    {
      "epoch": 2.006394884092726,
      "grad_norm": 0.8060266971588135,
      "learning_rate": 0.0003,
      "loss": 0.2438,
      "step": 2510
    },
    {
      "epoch": 2.014388489208633,
      "grad_norm": 0.7074018120765686,
      "learning_rate": 0.0003,
      "loss": 0.2439,
      "step": 2520
    },
    {
      "epoch": 2.0223820943245405,
      "grad_norm": 0.5800612568855286,
      "learning_rate": 0.0003,
      "loss": 0.2293,
      "step": 2530
    },
    {
      "epoch": 2.0303756994404476,
      "grad_norm": 0.5713195204734802,
      "learning_rate": 0.0003,
      "loss": 0.2472,
      "step": 2540
    },
    {
      "epoch": 2.038369304556355,
      "grad_norm": 0.5776579976081848,
      "learning_rate": 0.0003,
      "loss": 0.2512,
      "step": 2550
    },
    {
      "epoch": 2.046362909672262,
      "grad_norm": 0.9580339193344116,
      "learning_rate": 0.0003,
      "loss": 0.2337,
      "step": 2560
    },
    {
      "epoch": 2.0543565147881693,
      "grad_norm": 0.7107874751091003,
      "learning_rate": 0.0003,
      "loss": 0.2375,
      "step": 2570
    },
    {
      "epoch": 2.062350119904077,
      "grad_norm": 0.7532491683959961,
      "learning_rate": 0.0003,
      "loss": 0.248,
      "step": 2580
    },
    {
      "epoch": 2.070343725019984,
      "grad_norm": 0.8775434494018555,
      "learning_rate": 0.0003,
      "loss": 0.2528,
      "step": 2590
    },
    {
      "epoch": 2.0783373301358914,
      "grad_norm": 0.6331047415733337,
      "learning_rate": 0.0003,
      "loss": 0.2499,
      "step": 2600
    },
    {
      "epoch": 2.0863309352517985,
      "grad_norm": 0.8068843483924866,
      "learning_rate": 0.0003,
      "loss": 0.2568,
      "step": 2610
    },
    {
      "epoch": 2.094324540367706,
      "grad_norm": 0.7384593486785889,
      "learning_rate": 0.0003,
      "loss": 0.2519,
      "step": 2620
    },
    {
      "epoch": 2.102318145483613,
      "grad_norm": 0.8515192270278931,
      "learning_rate": 0.0003,
      "loss": 0.2516,
      "step": 2630
    },
    {
      "epoch": 2.1103117505995206,
      "grad_norm": 0.8294481635093689,
      "learning_rate": 0.0003,
      "loss": 0.2372,
      "step": 2640
    },
    {
      "epoch": 2.1183053557154277,
      "grad_norm": 0.6840695738792419,
      "learning_rate": 0.0003,
      "loss": 0.2452,
      "step": 2650
    },
    {
      "epoch": 2.1262989608313347,
      "grad_norm": 1.4625566005706787,
      "learning_rate": 0.0003,
      "loss": 0.2395,
      "step": 2660
    },
    {
      "epoch": 2.1342925659472423,
      "grad_norm": 0.5348649621009827,
      "learning_rate": 0.0003,
      "loss": 0.2467,
      "step": 2670
    },
    {
      "epoch": 2.1422861710631493,
      "grad_norm": 0.6464291214942932,
      "learning_rate": 0.0003,
      "loss": 0.2307,
      "step": 2680
    },
    {
      "epoch": 2.150279776179057,
      "grad_norm": 0.8175440430641174,
      "learning_rate": 0.0003,
      "loss": 0.2419,
      "step": 2690
    },
    {
      "epoch": 2.158273381294964,
      "grad_norm": 0.8021294474601746,
      "learning_rate": 0.0003,
      "loss": 0.252,
      "step": 2700
    },
    {
      "epoch": 2.1662669864108715,
      "grad_norm": 0.8437513709068298,
      "learning_rate": 0.0003,
      "loss": 0.2542,
      "step": 2710
    },
    {
      "epoch": 2.1742605915267785,
      "grad_norm": 0.7389939427375793,
      "learning_rate": 0.0003,
      "loss": 0.2459,
      "step": 2720
    },
    {
      "epoch": 2.182254196642686,
      "grad_norm": 0.7063220739364624,
      "learning_rate": 0.0003,
      "loss": 0.2348,
      "step": 2730
    },
    {
      "epoch": 2.190247801758593,
      "grad_norm": 0.5540182590484619,
      "learning_rate": 0.0003,
      "loss": 0.249,
      "step": 2740
    },
    {
      "epoch": 2.1982414068745,
      "grad_norm": 0.9057738184928894,
      "learning_rate": 0.0003,
      "loss": 0.261,
      "step": 2750
    },
    {
      "epoch": 2.2062350119904077,
      "grad_norm": 1.1086692810058594,
      "learning_rate": 0.0003,
      "loss": 0.2473,
      "step": 2760
    },
    {
      "epoch": 2.214228617106315,
      "grad_norm": 1.2130805253982544,
      "learning_rate": 0.0003,
      "loss": 0.2431,
      "step": 2770
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.7173119783401489,
      "learning_rate": 0.0003,
      "loss": 0.2564,
      "step": 2780
    },
    {
      "epoch": 2.2302158273381294,
      "grad_norm": 2.137937307357788,
      "learning_rate": 0.0003,
      "loss": 0.2649,
      "step": 2790
    },
    {
      "epoch": 2.238209432454037,
      "grad_norm": 1.4174240827560425,
      "learning_rate": 0.0003,
      "loss": 0.2452,
      "step": 2800
    },
    {
      "epoch": 2.246203037569944,
      "grad_norm": 0.7890908122062683,
      "learning_rate": 0.0003,
      "loss": 0.2467,
      "step": 2810
    },
    {
      "epoch": 2.2541966426858515,
      "grad_norm": 0.9340463876724243,
      "learning_rate": 0.0003,
      "loss": 0.2536,
      "step": 2820
    },
    {
      "epoch": 2.2621902478017586,
      "grad_norm": 0.6916820406913757,
      "learning_rate": 0.0003,
      "loss": 0.231,
      "step": 2830
    },
    {
      "epoch": 2.2701838529176657,
      "grad_norm": 0.5293393135070801,
      "learning_rate": 0.0003,
      "loss": 0.2465,
      "step": 2840
    },
    {
      "epoch": 2.278177458033573,
      "grad_norm": 0.5935090184211731,
      "learning_rate": 0.0003,
      "loss": 0.243,
      "step": 2850
    },
    {
      "epoch": 2.2861710631494803,
      "grad_norm": 0.6834856271743774,
      "learning_rate": 0.0003,
      "loss": 0.2165,
      "step": 2860
    },
    {
      "epoch": 2.294164668265388,
      "grad_norm": 0.8004593253135681,
      "learning_rate": 0.0003,
      "loss": 0.2283,
      "step": 2870
    },
    {
      "epoch": 2.302158273381295,
      "grad_norm": 0.7155677080154419,
      "learning_rate": 0.0003,
      "loss": 0.2437,
      "step": 2880
    },
    {
      "epoch": 2.3101518784972024,
      "grad_norm": 1.334281325340271,
      "learning_rate": 0.0003,
      "loss": 0.2356,
      "step": 2890
    },
    {
      "epoch": 2.3181454836131095,
      "grad_norm": 0.7281272411346436,
      "learning_rate": 0.0003,
      "loss": 0.2489,
      "step": 2900
    },
    {
      "epoch": 2.326139088729017,
      "grad_norm": 0.7096025943756104,
      "learning_rate": 0.0003,
      "loss": 0.2465,
      "step": 2910
    },
    {
      "epoch": 2.334132693844924,
      "grad_norm": 0.9171558618545532,
      "learning_rate": 0.0003,
      "loss": 0.2427,
      "step": 2920
    },
    {
      "epoch": 2.3421262989608316,
      "grad_norm": 0.6913008689880371,
      "learning_rate": 0.0003,
      "loss": 0.2486,
      "step": 2930
    },
    {
      "epoch": 2.3501199040767387,
      "grad_norm": 0.8998280763626099,
      "learning_rate": 0.0003,
      "loss": 0.2592,
      "step": 2940
    },
    {
      "epoch": 2.3581135091926457,
      "grad_norm": 0.6254902482032776,
      "learning_rate": 0.0003,
      "loss": 0.2372,
      "step": 2950
    },
    {
      "epoch": 2.3661071143085532,
      "grad_norm": 1.1087535619735718,
      "learning_rate": 0.0003,
      "loss": 0.2475,
      "step": 2960
    },
    {
      "epoch": 2.3741007194244603,
      "grad_norm": 0.7696303129196167,
      "learning_rate": 0.0003,
      "loss": 0.2472,
      "step": 2970
    },
    {
      "epoch": 2.382094324540368,
      "grad_norm": 0.8869982957839966,
      "learning_rate": 0.0003,
      "loss": 0.2414,
      "step": 2980
    },
    {
      "epoch": 2.390087929656275,
      "grad_norm": 0.7575953602790833,
      "learning_rate": 0.0003,
      "loss": 0.2399,
      "step": 2990
    },
    {
      "epoch": 2.3980815347721824,
      "grad_norm": 1.5456746816635132,
      "learning_rate": 0.0003,
      "loss": 0.2605,
      "step": 3000
    },
    {
      "epoch": 2.4060751398880895,
      "grad_norm": 0.7533592581748962,
      "learning_rate": 0.0003,
      "loss": 0.2256,
      "step": 3010
    },
    {
      "epoch": 2.4140687450039966,
      "grad_norm": 0.6602205038070679,
      "learning_rate": 0.0003,
      "loss": 0.2435,
      "step": 3020
    },
    {
      "epoch": 2.422062350119904,
      "grad_norm": 0.6059476733207703,
      "learning_rate": 0.0003,
      "loss": 0.2475,
      "step": 3030
    },
    {
      "epoch": 2.430055955235811,
      "grad_norm": 0.7386906147003174,
      "learning_rate": 0.0003,
      "loss": 0.2555,
      "step": 3040
    },
    {
      "epoch": 2.4380495603517187,
      "grad_norm": 0.6918269395828247,
      "learning_rate": 0.0003,
      "loss": 0.2366,
      "step": 3050
    },
    {
      "epoch": 2.446043165467626,
      "grad_norm": 0.4832334518432617,
      "learning_rate": 0.0003,
      "loss": 0.2483,
      "step": 3060
    },
    {
      "epoch": 2.4540367705835333,
      "grad_norm": 0.7615755200386047,
      "learning_rate": 0.0003,
      "loss": 0.2471,
      "step": 3070
    },
    {
      "epoch": 2.4620303756994404,
      "grad_norm": 0.9487646222114563,
      "learning_rate": 0.0003,
      "loss": 0.2701,
      "step": 3080
    },
    {
      "epoch": 2.470023980815348,
      "grad_norm": 0.7801991105079651,
      "learning_rate": 0.0003,
      "loss": 0.2387,
      "step": 3090
    },
    {
      "epoch": 2.478017585931255,
      "grad_norm": 0.5544376373291016,
      "learning_rate": 0.0003,
      "loss": 0.2383,
      "step": 3100
    },
    {
      "epoch": 2.4860111910471625,
      "grad_norm": 0.7632901668548584,
      "learning_rate": 0.0003,
      "loss": 0.2667,
      "step": 3110
    },
    {
      "epoch": 2.4940047961630696,
      "grad_norm": 0.6435315012931824,
      "learning_rate": 0.0003,
      "loss": 0.2436,
      "step": 3120
    },
    {
      "epoch": 2.5019984012789767,
      "grad_norm": 0.6745437383651733,
      "learning_rate": 0.0003,
      "loss": 0.2423,
      "step": 3130
    },
    {
      "epoch": 2.509992006394884,
      "grad_norm": 0.578331708908081,
      "learning_rate": 0.0003,
      "loss": 0.2264,
      "step": 3140
    },
    {
      "epoch": 2.5179856115107913,
      "grad_norm": 1.087524652481079,
      "learning_rate": 0.0003,
      "loss": 0.2624,
      "step": 3150
    },
    {
      "epoch": 2.5259792166266988,
      "grad_norm": 0.9948973655700684,
      "learning_rate": 0.0003,
      "loss": 0.2418,
      "step": 3160
    },
    {
      "epoch": 2.533972821742606,
      "grad_norm": 0.3700670897960663,
      "learning_rate": 0.0003,
      "loss": 0.2235,
      "step": 3170
    },
    {
      "epoch": 2.5419664268585134,
      "grad_norm": 1.3556571006774902,
      "learning_rate": 0.0003,
      "loss": 0.2365,
      "step": 3180
    },
    {
      "epoch": 2.5499600319744204,
      "grad_norm": 0.7468887567520142,
      "learning_rate": 0.0003,
      "loss": 0.2477,
      "step": 3190
    },
    {
      "epoch": 2.5579536370903275,
      "grad_norm": 0.6552057862281799,
      "learning_rate": 0.0003,
      "loss": 0.2284,
      "step": 3200
    },
    {
      "epoch": 2.565947242206235,
      "grad_norm": 0.8880707621574402,
      "learning_rate": 0.0003,
      "loss": 0.2509,
      "step": 3210
    },
    {
      "epoch": 2.573940847322142,
      "grad_norm": 0.6710386872291565,
      "learning_rate": 0.0003,
      "loss": 0.2433,
      "step": 3220
    },
    {
      "epoch": 2.5819344524380496,
      "grad_norm": 0.6196773052215576,
      "learning_rate": 0.0003,
      "loss": 0.2352,
      "step": 3230
    },
    {
      "epoch": 2.5899280575539567,
      "grad_norm": 1.2497674226760864,
      "learning_rate": 0.0003,
      "loss": 0.2497,
      "step": 3240
    },
    {
      "epoch": 2.5979216626698642,
      "grad_norm": 0.6452771425247192,
      "learning_rate": 0.0003,
      "loss": 0.239,
      "step": 3250
    },
    {
      "epoch": 2.6059152677857713,
      "grad_norm": 0.6474456787109375,
      "learning_rate": 0.0003,
      "loss": 0.2397,
      "step": 3260
    },
    {
      "epoch": 2.6139088729016784,
      "grad_norm": 0.7340297102928162,
      "learning_rate": 0.0003,
      "loss": 0.2364,
      "step": 3270
    },
    {
      "epoch": 2.621902478017586,
      "grad_norm": 0.679858386516571,
      "learning_rate": 0.0003,
      "loss": 0.2461,
      "step": 3280
    },
    {
      "epoch": 2.6298960831334934,
      "grad_norm": 2.0417561531066895,
      "learning_rate": 0.0003,
      "loss": 0.2483,
      "step": 3290
    },
    {
      "epoch": 2.6378896882494005,
      "grad_norm": 0.6943557262420654,
      "learning_rate": 0.0003,
      "loss": 0.2332,
      "step": 3300
    },
    {
      "epoch": 2.6458832933653076,
      "grad_norm": 0.7364160418510437,
      "learning_rate": 0.0003,
      "loss": 0.234,
      "step": 3310
    },
    {
      "epoch": 2.653876898481215,
      "grad_norm": 0.5560287237167358,
      "learning_rate": 0.0003,
      "loss": 0.2425,
      "step": 3320
    },
    {
      "epoch": 2.661870503597122,
      "grad_norm": 0.7772321105003357,
      "learning_rate": 0.0003,
      "loss": 0.2531,
      "step": 3330
    },
    {
      "epoch": 2.6698641087130297,
      "grad_norm": 0.6119484305381775,
      "learning_rate": 0.0003,
      "loss": 0.2487,
      "step": 3340
    },
    {
      "epoch": 2.677857713828937,
      "grad_norm": 0.7422016859054565,
      "learning_rate": 0.0003,
      "loss": 0.2493,
      "step": 3350
    },
    {
      "epoch": 2.6858513189448443,
      "grad_norm": 0.7699691653251648,
      "learning_rate": 0.0003,
      "loss": 0.2565,
      "step": 3360
    },
    {
      "epoch": 2.6938449240607514,
      "grad_norm": 0.7944760322570801,
      "learning_rate": 0.0003,
      "loss": 0.2575,
      "step": 3370
    },
    {
      "epoch": 2.7018385291766585,
      "grad_norm": 0.6599855422973633,
      "learning_rate": 0.0003,
      "loss": 0.2569,
      "step": 3380
    },
    {
      "epoch": 2.709832134292566,
      "grad_norm": 1.0945152044296265,
      "learning_rate": 0.0003,
      "loss": 0.2498,
      "step": 3390
    },
    {
      "epoch": 2.7178257394084735,
      "grad_norm": 1.7514700889587402,
      "learning_rate": 0.0003,
      "loss": 0.2432,
      "step": 3400
    },
    {
      "epoch": 2.7258193445243806,
      "grad_norm": 1.4970251321792603,
      "learning_rate": 0.0003,
      "loss": 0.2537,
      "step": 3410
    },
    {
      "epoch": 2.7338129496402876,
      "grad_norm": 0.7870901823043823,
      "learning_rate": 0.0003,
      "loss": 0.2414,
      "step": 3420
    },
    {
      "epoch": 2.741806554756195,
      "grad_norm": 0.5042044520378113,
      "learning_rate": 0.0003,
      "loss": 0.2521,
      "step": 3430
    },
    {
      "epoch": 2.7498001598721022,
      "grad_norm": 0.6886523962020874,
      "learning_rate": 0.0003,
      "loss": 0.2358,
      "step": 3440
    },
    {
      "epoch": 2.7577937649880093,
      "grad_norm": 0.5846215486526489,
      "learning_rate": 0.0003,
      "loss": 0.24,
      "step": 3450
    },
    {
      "epoch": 2.765787370103917,
      "grad_norm": 0.7734375596046448,
      "learning_rate": 0.0003,
      "loss": 0.2366,
      "step": 3460
    },
    {
      "epoch": 2.7737809752198244,
      "grad_norm": 0.5096850395202637,
      "learning_rate": 0.0003,
      "loss": 0.2572,
      "step": 3470
    },
    {
      "epoch": 2.7817745803357314,
      "grad_norm": 0.6845677495002747,
      "learning_rate": 0.0003,
      "loss": 0.2483,
      "step": 3480
    },
    {
      "epoch": 2.7897681854516385,
      "grad_norm": 0.6258018612861633,
      "learning_rate": 0.0003,
      "loss": 0.2573,
      "step": 3490
    },
    {
      "epoch": 2.797761790567546,
      "grad_norm": 0.6683380603790283,
      "learning_rate": 0.0003,
      "loss": 0.2434,
      "step": 3500
    },
    {
      "epoch": 2.805755395683453,
      "grad_norm": 0.9433270692825317,
      "learning_rate": 0.0003,
      "loss": 0.2428,
      "step": 3510
    },
    {
      "epoch": 2.8137490007993606,
      "grad_norm": 0.9451518654823303,
      "learning_rate": 0.0003,
      "loss": 0.2458,
      "step": 3520
    },
    {
      "epoch": 2.8217426059152677,
      "grad_norm": 1.1010289192199707,
      "learning_rate": 0.0003,
      "loss": 0.2301,
      "step": 3530
    },
    {
      "epoch": 2.8297362110311752,
      "grad_norm": 0.8693906664848328,
      "learning_rate": 0.0003,
      "loss": 0.2466,
      "step": 3540
    },
    {
      "epoch": 2.8377298161470823,
      "grad_norm": 0.7519054412841797,
      "learning_rate": 0.0003,
      "loss": 0.243,
      "step": 3550
    },
    {
      "epoch": 2.8457234212629894,
      "grad_norm": 0.8420125246047974,
      "learning_rate": 0.0003,
      "loss": 0.2538,
      "step": 3560
    },
    {
      "epoch": 2.853717026378897,
      "grad_norm": 1.2885392904281616,
      "learning_rate": 0.0003,
      "loss": 0.2485,
      "step": 3570
    },
    {
      "epoch": 2.8617106314948044,
      "grad_norm": 1.2009209394454956,
      "learning_rate": 0.0003,
      "loss": 0.2454,
      "step": 3580
    },
    {
      "epoch": 2.8697042366107115,
      "grad_norm": 1.0680980682373047,
      "learning_rate": 0.0003,
      "loss": 0.2482,
      "step": 3590
    },
    {
      "epoch": 2.8776978417266186,
      "grad_norm": 0.6893447041511536,
      "learning_rate": 0.0003,
      "loss": 0.2766,
      "step": 3600
    },
    {
      "epoch": 2.885691446842526,
      "grad_norm": 1.1247546672821045,
      "learning_rate": 0.0003,
      "loss": 0.2501,
      "step": 3610
    },
    {
      "epoch": 2.893685051958433,
      "grad_norm": 1.166717290878296,
      "learning_rate": 0.0003,
      "loss": 0.2468,
      "step": 3620
    },
    {
      "epoch": 2.9016786570743403,
      "grad_norm": 0.7954961657524109,
      "learning_rate": 0.0003,
      "loss": 0.2396,
      "step": 3630
    },
    {
      "epoch": 2.9096722621902478,
      "grad_norm": 1.0188298225402832,
      "learning_rate": 0.0003,
      "loss": 0.2438,
      "step": 3640
    },
    {
      "epoch": 2.9176658673061553,
      "grad_norm": 1.393891453742981,
      "learning_rate": 0.0003,
      "loss": 0.2308,
      "step": 3650
    },
    {
      "epoch": 2.9256594724220624,
      "grad_norm": 0.725470244884491,
      "learning_rate": 0.0003,
      "loss": 0.2566,
      "step": 3660
    },
    {
      "epoch": 2.9336530775379694,
      "grad_norm": 0.7775665521621704,
      "learning_rate": 0.0003,
      "loss": 0.2488,
      "step": 3670
    },
    {
      "epoch": 2.941646682653877,
      "grad_norm": 1.3229849338531494,
      "learning_rate": 0.0003,
      "loss": 0.2285,
      "step": 3680
    },
    {
      "epoch": 2.949640287769784,
      "grad_norm": 0.6760865449905396,
      "learning_rate": 0.0003,
      "loss": 0.2446,
      "step": 3690
    },
    {
      "epoch": 2.9576338928856916,
      "grad_norm": 0.5219919681549072,
      "learning_rate": 0.0003,
      "loss": 0.2527,
      "step": 3700
    },
    {
      "epoch": 2.9656274980015986,
      "grad_norm": 1.0030547380447388,
      "learning_rate": 0.0003,
      "loss": 0.2542,
      "step": 3710
    },
    {
      "epoch": 2.973621103117506,
      "grad_norm": 0.5916932225227356,
      "learning_rate": 0.0003,
      "loss": 0.2337,
      "step": 3720
    },
    {
      "epoch": 2.9816147082334132,
      "grad_norm": 0.8422384262084961,
      "learning_rate": 0.0003,
      "loss": 0.2568,
      "step": 3730
    },
    {
      "epoch": 2.9896083133493203,
      "grad_norm": 0.7558164000511169,
      "learning_rate": 0.0003,
      "loss": 0.2401,
      "step": 3740
    },
    {
      "epoch": 2.997601918465228,
      "grad_norm": 0.8851986527442932,
      "learning_rate": 0.0003,
      "loss": 0.2644,
      "step": 3750
    },
    {
      "epoch": 3.0,
      "step": 3753,
      "total_flos": 1.7896742946865152e+17,
      "train_loss": 0.2512018846696833,
      "train_runtime": 13761.0496,
      "train_samples_per_second": 2.18,
      "train_steps_per_second": 0.273
    }
  ],
  "logging_steps": 10,
  "max_steps": 3753,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7896742946865152e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
